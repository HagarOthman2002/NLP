# -*- coding: utf-8 -*-
"""session 2 NLP

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1E7n68MwrVGNrCFM08RTSufYeVJmQ0_12
"""

import nltk
nltk.download('punkt') #tokenization (word , sentence)

"""#tokenizers"""

text = 'Hello! How are you doing today? I hope you"re having a good day '
sentences = nltk.sent_tokenize(text) # tokenize sentencses
words = nltk.word_tokenize(text) # tokenize words on the text itself
print(sentences)
print(words)

"""#stop words"""

import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# stopwords.words('arabic')
len(set(stopwords.words('arabic')))

arabic_text = "قامت الشركة باصدار بيانات تفصيلية حول ادائها فى الربع الاول من العام الحالى"
words = word_tokenize(arabic_text)
print(len(words))
print(words)

stop_words = set(stopwords.words('arabic'))
filtered_words =  [word for word in words if not word in stop_words]
print(len(filtered_words))
print(filtered_words)

result = ' '.join(filtered_words)
result

#English stop words
text = 'Hello! How are you doing today? I hope you"re having a good day '
words = word_tokenize(text)
print(len(words))
print(words)

stop_words = set(stopwords.words('english'))
filtered_words = [word for word in words if  word.lower() not in stop_words] # must lower case to remove (I)
print(len(filtered_words))
print(filtered_words)

result = ' '.join(filtered_words)
print(result)

"""#stemming"""

from nltk.stem import PorterStemmer

stemmer = PorterStemmer()

words = ["walking" , "jumps" , "jumping"]

for word in words:
  stemmed_Word = stemmer.stem(word)
  print(f'{word}>>>>{stemmed_Word}')

"""#lemmitization"""

nltk.download("wordnet") #wordnet applying lemmiztization
from nltk.stem import PorterStemmer , WordNetLemmatizer

text = 'the quick brown foxes jumped over lazy dogs'

#stemming

stemmer =PorterStemmer()
stemmed_Words = [stemmer.stem(word) for word in word_tokenize(text)]
print(stemmed_Words)

#lemmitization

lemmetizer = WordNetLemmatizer()
lemmetized_Words = [lemmetizer.lemmatize(word) for word in word_tokenize(text)]
print(lemmetized_Words)

#lazi X lazy
#jump X jumped



"""#regexp
  - used on optical character recognation
"""

import re # library for regular expressions

text = '''Elon musk's number is 9631312891, call him if you have any question on dodgecoin.
Tesla's revenue is 40 billion
Tesla's CFO number (999)-333-7777
'''

# \d means any digit
pattern = '\d{3}'
result = re.findall(pattern , text )
result

#(999)-333-7777
# befor () we have to put \
pattern = '\(\d{3}\)-\d{3}-\d{4}'
result = re.findall(pattern , text)
result

#9631312891 , (999)-333-7777
pattern = '\d{10}|\(\d{3}\)-\d{3}-\d{4}'
result = re.findall(pattern , text)
result

#/d >>> digits
#. >>> distance
#\n>>> new line
# note(x)  #hat el x ely ablha note
#[^s] >>> excluded

text ='''
Note 1 - Overview

Tesla, Inc. ("Tesla", the "Company", "we", "us" or "our") was incorporated in the State of Delaware on July 1, 2003. We design, develop, manufacture and sell h
products. Our Chief Executive Officer, as the chief operating decision maker ("CODM"), organizes our company, manages resource allocations and measures perform
Beginning in the first quarter of 2021, there has been a trend in many parts of the world of increasing availability and administration of vaccines
against COVID-19, as well as an easing of restrictions on social, business, travel and government activities and functions. On the other hand, infection
rates and regulations continue to fluctuate in various regions and there are ongoing global impacts resulting from the pandemic, including challenges
and increases in costs for logistics and supply chains, such as increased port congestion, intermittent supplier delays and a shortfall of semiconductor
supply. We have also previously been affected by temporary manufacturing closures, employment and compensation adjustments and impediments to
administrative activities supporting our product deliveries and deployments.

Note 2 - Summary of Significant Accounting Policies
Unaudited Interim Financial Statements
The consolidated balance sheet as of September 30, 2021, the consolidated statements of operations, the consolidated statements of
comprehensive income, the consolidated statements of redeemable noncontrolling interests and equity for the three and nine months ended September
30, 2021 and 2020 and the consolidated statements of cash flows for the nine months ended September 30, 2021 and 2020, as well as other information
disclosed in the accompanying notes, are unaudited. The consolidated balance sheet as of December 31, 2020 was derived from the audited
consolidated financial statements as of that date. The interim consolidated financial statements and the accompanying notes should be read in
conjunction with the annual consolidated financial statements and the accompanying notes contained in our Annual Report on Form 10-K for the year
ended December 31, 2020.'''

#\d>>>>> digits
#.>>>>>> distancce
#*>>>>>> the rest of character
#\n>>>>> new line
#note(x)
#[^a] >>> excluded

#Note 1 - Overview , Note 2 - Summary of Significant Accounting Policies
pattern = 'Note.\d.-.[^\n]*'
res = re.findall(pattern , text)
res

#Note 1 - Overview , Note 2 - Summary of Significant Accounting Policies
pattern = 'Note.\d.-.([^\n]*)'
res = re.findall(pattern , text)
res

#regex website

"""#POS"""

import spacy
!python -m spacy download en_core_web_sm  # en_core_web_sm pre traned model to deal with pos and NER

nlp = spacy.load('en_core_web_sm')
doc = nlp('Elon flew to mars yesterday . He carried biryani masal with him')
for token in doc:
  print(token , ' ||' , token.pos_ , ' ||' , spacy.explain(token.pos_ ))

